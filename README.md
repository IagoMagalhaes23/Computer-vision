# Computer Vision

## Introdu√ß√£o
Buscando aprender mais sobre Vis√£o Computacional e seus principais recursos. Tenho buscado conhecimento em diferentes plataformas e desenvolvendo aplica√ß√µes em Python para praticar e criar habilidades nesse campo. Neste reposit√≥rio busco aprender sobre Yolo e suas vers√µes, Detectron 2, MediaPipe, OpenCV, Scikit Image e et.

## Projetos

### Projeto 1:
- An√°lise facial para detec√ß√£o de sono
Na primeira etapa do curso aprendir sobre como estruturar um projeto de vis√£o computacional, utilizar a captura de imagens em tempo real com OpenCv, detectar faces com MediaPipe Face Mesh e construir uma visualiza√ß√£o de pontos daciais. O resultado pode ser visualizado na imagem abaixo.

Na segunda etapa do curso foi apresentado como identificar as coordenadas e os pontos da solu√ß√£o Face mesh, localizar e exibir os pontos que representam os olhos direito e esquerdo, interpretar as coordenadas do mediapipe e calcular o valor de EAR.

Na terceira aula foi abordado sobre como localizar e exibir os pontos que representam a boca, e por fim formular e implementar o c√°lculo do √≠ndice de n√≠vel de abertura da boca, o MAR.

Na √∫ltima aula, conseguir aprender sobre como utilizar as funcionalidades do mediapipe para identificar o olho, contar o n√∫mero de piscadas, verificar a frequencia de eventos e identificar se o usu√°rio est√° dormindo ou n√£o.

Sugest√µes de melhorias futuras: integrar o projeto de an√°lise facial ao um sistema com microcontrolador e emitir bips ou efeitos sonoros e luminosos para ajudar o usu√°rio acordar e alertar as pessoas em volta para auxiliar na situa√ß√£o.

### Projeto 2:
- Depth Anything: Como Criar Mapas de Profundidade

A percep√ß√£o de profundidade √© o que nos permite interpretar o mundo tridimensional a partir de imagens bidimensionais projetadas em nossas retinas. Essa habilidade evoluiu como um aspecto crucial para a sobreviv√™ncia, possibilitando aos humanos navegar pelo ambiente, evitar predadores e localizar recursos.

O c√©rebro humano realiza essa fa√ßanha por meio de uma s√©rie de interpreta√ß√µes das informa√ß√µes visuais, onde a sobreposi√ß√£o do campo visual binocular fornece uma rica percep√ß√£o de profundidade.

Al√©m da vis√£o binocular, essa percep√ß√£o √© enriquecida por v√°rias pistas monoculares (depth cues), elementos no ambiente que permitem ao observador √∫nico inferir a profundidade mesmo com um olho fechado. Entre essas pistas est√£o occlus√£o, tamanho relativo, sombras projetadas, e perspectiva linear.

Esses mesmos princ√≠pios e mecanismos de percep√ß√£o encontram um paralelo na Vis√£o Computacional, onde a ess√™ncia da estimativa tamb√©m reside em capturar a estrutura espacial de uma cena para representar com precis√£o seus aspectos tridimensionais.

O modelo Depth Anything, introduzido no trabalho ‚ÄúDepth Anything: Unleashing the Power of Large-Scale Unlabeled Data‚Äù, representa um avan√ßo significativo em estimativa de profundidade monocular. Baseado na arquitetura DPT (Dense Prediction Transformer), foi treinado em um vasto conjunto de dados com mais de 62 milh√µes de imagens n√£o rotuladas.

O sucesso desta abordagem √© atribu√≠do a duas estrat√©gias principais.

- A utiliza√ß√£o de ferramentas de data augmentation para estabelecer um target de otimiza√ß√£o mais desafiador.
- Uso de supervis√£o auxiliar para assegurar a heran√ßa de priores sem√¢nticos a partir de codificadores pr√©-treinados.

A capacidade de generaliza√ß√£o do Depth Anything, testada em seis conjuntos de dados p√∫blicos e em fotografias capturadas aleatoriamente, superou algumas m√©tricas de modelos existentes, como MiDaS v3.1 e ZoeDepth.

Ess√™ncia da Percep√ß√£o de Profundidade Monocular: A estimativa de profundidade monocular √© fundamental para compreender a estrutura espacial de uma cena a partir de uma √∫nica imagem, permitindo aplica√ß√µes como reconstru√ß√£o 3D de cenas.

Avan√ßos com Depth Anything: Representando um salto significativo na percep√ß√£o de profundidade monocular, o modelo Depth Anything utiliza a arquitetura DPT e foi treinado em um conjunto de dados extenso, mostrando excelente capacidade de generaliza√ß√£o.

Aplica√ß√£o Pr√°tica: O artigo fornece instru√ß√µes detalhadas para testar a estimativa de profundidade com imagens e v√≠deos, facilitando a experimenta√ß√£o pr√°tica e a visualiza√ß√£o dos resultados do modelo Depth Anything. A imagem 01 apresenta um pouco de como o algoritmo pode ser utilizado.

![image](https://github.com/IagoMagalhaes23/Computer-vision/assets/65053026/82f76c6e-5d49-46ee-b817-e13306d28d15)

### Projeto 3:
- YOLO: Segmenta√ß√£o de Objetos | A Poderosa Capacidade do YOLO Explorada Passo a Passo
Descubra a incr√≠vel capacidade de segmenta√ß√£o de objetos do YOLO neste tutorial abrangente! üöÄ Aprenda como o YOLO (You Only Look Once) pode identificar e delimitar objetos em tempo real, revolucionando a vis√£o computacional. Aqui exploramos as v√°rias funcionalidades do YOLO, incluindo detec√ß√£o de objetos, classifica√ß√£o e segmenta√ß√£o, fornecendo insights valiosos para iniciantes e entusiastas avan√ßados de IA e vis√£o computacional.

### Projeto 4:
No projeto 04, com a ajuda do canal WellingtonDev25 (nome de usu√°rio no GitHub) criamos um pequeno programa para prever a dist√¢nica da m√£o em rela√ß√£o a camera.

## Refer√™ncias
- (Projeto An√°lise facial): Curso de Vis√£o Computacional: An√°lise facial; Curso presente na Alura com aulas ministradas pela professora Mirla Costa.
- [Depth Anything: Como Criar Mapas de Profundidade](https://sigmoidal.ai/depth-anything-como-criar-mapas-de-profundidade/)
- [YOLO: Segmenta√ß√£o de Objetos | A Poderosa Capacidade do YOLO Explorada Passo a Passo](https://youtu.be/r6tQtIeWXu8?si=uIERQkTcDl0OFMCq)
- [Dist√¢ncia M√£o](https://github.com/WellingtonDev25/distancia_mao/tree/main